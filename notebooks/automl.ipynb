{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training with Automated ML\n",
    "\n",
    "In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'azureml-sdk'\n",
    "!pip install 'azureml-sdk[notebooks]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure ML Imports\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "source": [
    "## Workspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "source": [
    "## Compute\n",
    "\n",
    "Create a remote GPU compute cluster for model training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a name for your CPU cluster\n",
    "gpu_cluster_name = \"gpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    gpu_cluster = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC24',\n",
    "                                                           max_nodes=10)\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "\n",
    "gpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
    "\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://www.kaggle.com/datamunge/sign-language-mnist\"\n",
    "\n",
    "found = False\n",
    "key = \"sign-language-mnist\"\n",
    "description_text = \"sign Language MNIST\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "    found = True\n",
    "    ds = ws.datasets[key] \n",
    "\n",
    "if not found:\n",
    "    from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "    datastore_path = \"https://github.com/emanbuc/ASL-Recognition-Deep-Learning/raw/main/datasets/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\"\n",
    "    ds = TabularDatasetFactory.from_delimited_files(path=datastore_path,header=True)       \n",
    "    #Register Dataset in Workspace\n",
    "    ds = ds.register(workspace=ws,\n",
    "                                   name=key,\n",
    "                                   description=description_text)\n",
    "\n",
    "\n",
    "df = ds.to_pandas_dataframe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "**max_concurrent_iterations** : 10\n",
    "\n",
    "AmlCompute clusters support one interation running per node. For multiple AutoML experiment parent runs executed in parallel on a single AmlCompute cluster, the sum of the max_concurrent_iterations values for all experiments should be less than or equal to the maximum number of nodes. Otherwise, runs will be queued until nodes are available.\n",
    "Set to 10 as number of node in compute cluster.\n",
    "\n",
    "**iteration_timeout_minutes** : 10\n",
    "\n",
    "Maximum time in minutes that each iteration can run for before it terminates. 30 minutes to avoid Lab timeout.\n",
    "\n",
    "**experiment_timeout_hours**: 0.5\n",
    "\n",
    "Experiment must end before lab timeout\n",
    "\n",
    "**enable_early_stopping**: true\n",
    "\n",
    "Whether to enable early termination if the score is not improving in the short term. Set to True to avoid waste time. We don't need to try every possible iteration in this demo experiment.\n",
    "\n",
    "**enable_onnx_compatible_models**: True\n",
    "\n",
    "Whether to enable or disable enforcing the ONNX-compatible models. Must be True to anable deploy on ONNX runtime.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"experiment_timeout_hours\" : 0.5,\n",
    "    \"enable_early_stopping\" : True,\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"max_concurrent_iterations\": 10,\n",
    "    \"enable_onnx_compatible_models\": True\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    debug_log='automl_errors.log',\n",
    "    compute_target=gpu_cluster,\n",
    "    task='classification',\n",
    "    primary_metric='accuracy',\n",
    "    training_data= ds,\n",
    "    label_column_name='label',\n",
    "    **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit AutoML Experiment\n",
    "experiment_name = 'ASL-DeepLearning-AutoML'\n",
    "exp_automl = Experiment(workspace=ws, experiment_name)\n",
    "automl_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "automl_run = automl_experiment.submit(automl_config)\n",
    "RunDetails(automl_run).show()\n",
    "automl_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_automl_run, auto_ml_fitted_model = automl_run.get_output()\n",
    "print(best_automl_run)\n",
    "print(auto_ml_fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=auto_ml_fitted_model.steps[1][1]\n",
    "vc.named_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Save the best model\n",
    "model = best_automl_run.register_model(model_name='automl-model', model_path='outputs/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}