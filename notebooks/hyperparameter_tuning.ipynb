{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train model - No HyperDrive"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azureml-sdk[notebooks]\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install tensorflow"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268351340
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure ML Imports\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.widgets import RunDetails"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268351555
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "experiment_name = 'ASL-DeepLearning-hyperameter'\n",
        "\n",
        "exp_with_hyper = Experiment(workspace=ws, name='Sign-Language-HyperDrive')\n",
        "exp_no_hyper = Experiment(workspace=ws, name='Sign-Language-NoHyperDrive')\n",
        "\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268352451
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for your CPU cluster\n",
        "cluster_name = \"gpu-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC24',\n",
        "                                                           max_nodes=10)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268352978
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://www.kaggle.com/datamunge/sign-language-mnist\"\n",
        "\n",
        "found = False\n",
        "key = \"sign-language-mnist\"\n",
        "description_text = \"sign Language MNIST\"\n",
        "\n",
        "if key in ws.datasets.keys(): \n",
        "    found = True\n",
        "    ds = ws.datasets[key] \n",
        "\n",
        "if not found:\n",
        "    from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "    datastore_path = \"https://github.com/emanbuc/ASL-Recognition-Deep-Learning/raw/main/datasets/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\"\n",
        "    ds = TabularDatasetFactory.from_delimited_files(path=datastore_path,header=True)       \n",
        "    #Register Dataset in Workspace\n",
        "    ds = ds.register(workspace=ws,\n",
        "                                   name=key,\n",
        "                                   description=description_text)\n",
        "\n",
        "\n",
        "df = ds.to_pandas_dataframe()\n",
        "df.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268367891
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To map each label number to its corresponding letter\n",
        "letters = dict(enumerate(string.ascii_uppercase))\n",
        "letters"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268368176
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "targets = pd.get_dummies(df.pop('label')).values\n",
        "data = df.values\n",
        "targets.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268368423
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268368638
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import minmax_scale\n",
        "data = minmax_scale(data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268368864
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (28,28, 1) # 28*28 = 784"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268368969
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.reshape(data,(-1, 28, 28,1))\n",
        "data.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268369366
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268369564
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPLITTING THE DATA Training set and Validation Set"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(data, targets , test_size = 0.2, random_state=0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268369848
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data to file for remote cluster\n",
        "\n",
        "Salva i dati prepatati su file con pickle e esegue upload verso datastore del workspace in cloud."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "if os.path.isfile('dataset/sign-language-mnist.pkl'):\n",
        "    print('File is present')\n",
        "else:\n",
        "    os.makedirs('dataset')\n",
        "    with open('dataset/sign-language-mnist.pkl','wb') as f:\n",
        "        pickle.dump((X_train,X_val,y_train,y_val),f)\n",
        "    \n",
        "    datastore=ws.get_default_datastore()\n",
        "    datastore.upload('./dataset', target_path='sign-language-mnist-data')\n",
        "\n",
        "print('Done')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268370228
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remote Trainig Experiment\n",
        "\n",
        "Create an estimator object to run training experiment in remote compute cluster"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.estimator import Estimator\n",
        "script_params = {\n",
        "    '--data_folder': ws.get_default_datastore(),\n",
        "    '--hidden': 100\n",
        "}\n",
        "\n",
        "est = Estimator(source_directory='.',\n",
        "                script_params=script_params,\n",
        "                compute_target=cpu_cluster,\n",
        "                entry_script='train_keras.py',\n",
        "                pip_packages=['keras','tensorflow'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268373877
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run = exp_no_hyper.submit(est)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268379997
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remote Training with Hyper Drive"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperdrive Configuration\n",
        "\n",
        "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive.policy import BanditPolicy,MedianStoppingPolicy\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, normal,choice"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611268380178
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Create the different params that you will be using during training\n",
        "param_sampling = RandomParameterSampling({\n",
        "         '--hidden': choice([50,100,200,300]),\n",
        "         '--batch_size': choice([64,128]), \n",
        "         '--epochs': choice([3,5,10]),\n",
        "         '--dropout': choice([0.5,0.8,1])})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268380276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
        "\n",
        "early_termination_policy = MedianStoppingPolicy()\n",
        "hd_config = HyperDriveConfig(estimator=est,\n",
        "  hyperparameter_sampling=param_sampling,\n",
        "  policy=early_termination_policy,\n",
        "  primary_metric_name='Accuracy',\n",
        "  primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "  max_total_runs=16,\n",
        "  max_concurrent_runs=4)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611268380459
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "param_sampling = RandomParameterSampling({\n",
        "         '--hidden': choice([50,100,200,300]),\n",
        "         '--batch_size': choice([64,128]), \n",
        "         '--epochs': choice([5,10,50]),\n",
        "         '--dropout': choice([0.5,0.8,1])})"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "hyperdrive_run = exp_with_hyper.submit(hd_config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611270165893
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(hyperdrive_run).show()\n",
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611269128716
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "assert(hyperdrive_run.get_status() == \"Completed\")\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "print(best_run.get_details()['runDefinition']['arguments'])\n",
        "print(best_run.get_file_names())\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "print('Best accuracy: {}'.format(best_run_metrics['Accuracy']))\n",
        "print('========================')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = best_run.register_model(model_name='mnist_model.hdf5', model_path='./outputs/mnist_model.hdf5')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run_metrics"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service.\n",
        "\n",
        "Deploy your model as a web service using Model.deploy(). Web services take one or more models, load them in an environment, and run them on one of several supported deployment targets.  For this example, we will deploy your scikit-learn model to an Azure Container Instance (ACI)."
      ],
      "metadata": {
        "gather": {
          "logged": 1598546650307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service_name = 'sign-language-service'\n",
        "\n",
        "service = Model.deploy(ws, service_name, [model], overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {}
    },
    {
      "source": [
        "## Test Deployed Model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_data: (7172, 785)\nX_test: (9, 784)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "test_data = pd.read_csv(\"../datasets/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\")\n",
        "print(\"test_data: \"+ str(test_data.shape))\n",
        "X_test=test_data.iloc[1:10,1:785]\n",
        "print(\"X_test: \" +str(X_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "testdict= X_test.to_dict(orient=\"index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Two sets of data to score, so we get two results back\n",
        "data = {\"data\": (testdict[1],testdict[2],testdict[3],testdict[4],testdict[5],testdict[5])}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# URL for the web service, should be similar to:\n",
        "# 'http://8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io/score'\n",
        "scoring_uri = 'http://fa662e2e-8a0a-419c-8258-af98c3380389.southcentralus.azurecontainer.io/score'\n",
        "# If the service is authenticated, set the key or token\n",
        "key = 'brhKng8SDm6C8QLQRuH7VqOsetHebyLC'\n",
        "\n",
        "# Convert to JSON string\n",
        "input_data = json.dumps(data)\n",
        "with open(\"data.json\", \"w\") as _f:\n",
        "    _f.write(input_data)\n",
        "\n",
        "# Set the content type\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "# If authentication is enabled, set the authorization header\n",
        "headers['Authorization'] = f'Bearer {key}'\n",
        "\n",
        "# Make the request and display the response\n",
        "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
        "print(resp.json())"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-5-37c78bcbd5eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Make the request and display the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mC:\\Python38\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    898\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python38\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python38\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python38\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "service.get_logs()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#cpu_cluster.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
        }
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3-final",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}